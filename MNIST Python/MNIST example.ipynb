{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4191de68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_size = 28 # (width/length)\n",
    "n_labels = 10 #  i.e. 0, 1, 2, 3, ..., 9 (10 digits)\n",
    "image_pixels = image_size*image_size\n",
    "\n",
    "data_path = \"MNIST/\"\n",
    "train_data = np.loadtxt(data_path + \"mnist_train.csv\", \n",
    "                        delimiter=\",\")\n",
    "test_data = np.loadtxt(data_path + \"mnist_test.csv\", \n",
    "                       delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8fe7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c3e68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be44e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d390bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fac = 0.99 / 255\n",
    "train_imgs = np.asfarray(train_data[:, 1:]) * fac + 0.01\n",
    "test_imgs = np.asfarray(test_data[:, 1:]) * fac + 0.01\n",
    "\n",
    "train_labels = np.asfarray(train_data[:, :1])\n",
    "test_labels = np.asfarray(test_data[:, :1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd31be9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a4b07d",
   "metadata": {},
   "source": [
    "### Converting the labels into one-hot representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6c0d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "digit = np.arange(10)\n",
    "\n",
    "for label in range(10):\n",
    "    one_hot = (digit==label).astype(int)\n",
    "    print(\"label: \", label, \" in one-hot representation: \", one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d86a6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "digit = np.arange(n_labels)\n",
    "\n",
    "# transform labels into one hot representation\n",
    "train_labels_one_hot = (digit==train_labels).astype(float)\n",
    "test_labels_one_hot = (digit==test_labels).astype(float)\n",
    "\n",
    "# we don't want zeroes and ones in the labels neither:\n",
    "train_labels_one_hot[train_labels_one_hot==0] = 0.01\n",
    "train_labels_one_hot[train_labels_one_hot==1] = 0.99\n",
    "test_labels_one_hot[test_labels_one_hot==0] = 0.01\n",
    "test_labels_one_hot[test_labels_one_hot==1] = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae5b808",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5678d84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec74ff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    img = train_imgs[i].reshape((28,28))\n",
    "    plt.imshow(img, cmap=\"Greys\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8749a376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"pickled_mnist.pkl\", \"bw\") as fh:\n",
    "    data = (train_imgs, \n",
    "            test_imgs, \n",
    "            train_labels,\n",
    "            test_labels)\n",
    "    \n",
    "    pickle.dump(data, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08a58a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickled_mnist.pkl\", \"br\") as fh:\n",
    "    data = pickle.load(fh)\n",
    "\n",
    "train_imgs = data[0]\n",
    "test_imgs = data[1]\n",
    "train_labels = data[2]\n",
    "test_labels = data[3]\n",
    "\n",
    "train_labels_one_hot = (digit==train_labels).astype(float)\n",
    "test_labels_one_hot = (digit==test_labels).astype(float)\n",
    "\n",
    "image_size = 28 # width and length\n",
    "no_of_different_labels = 10 #  i.e. 0, 1, 2, 3, ..., 9\n",
    "image_pixels = image_size * image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf027e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58f251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm\n",
    "\n",
    "def truncated_normal(mean=0, sd=1, low=0, upp=10):\n",
    "    return truncnorm(\n",
    "        (low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd)\n",
    "\n",
    "class MLP:\n",
    "    \n",
    "    def __init__(self, n_in, n_out, n_hidden, lr=0.1, bias=None):\n",
    "        self.n_in = n_in # the number of input nodes \n",
    "        self.n_out = n_out # the number ot output nodes\n",
    "        self.n_hidden = n_hidden # the number of hidden nodes\n",
    "        self.lr = lr # the learning rate\n",
    "        self.bias = bias\n",
    "        \n",
    "        self.weights()\n",
    "        \n",
    "    # a method to initialize the weight matrices (thetas)    \n",
    "    def weights(self):\n",
    "        \n",
    "        bias_node = 1 if self.bias else 0 \n",
    "        rad = 1 / np.sqrt(self.n_hidden + bias_node)\n",
    "        X = truncated_normal(mean=0, sd=1, low=-rad, upp=rad)\n",
    "        # the weights matrix connecting the input nodes with the hidden nodes\n",
    "        self.w_in_hidden = X.rvs((self.n_hidden, self.n_in+bias_node))\n",
    "        \n",
    "        rad = 1 / np.sqrt(self.n_hidden + bias_node)\n",
    "        X = truncated_normal(mean=0, sd=1, low=-rad, upp=rad)\n",
    "        # the weights matrix connecting the hidden nodes with the output nodes\n",
    "        self.w_hidden_out = X.rvs((self.n_out, self.n_hidden+bias_node))\n",
    "        \n",
    "        \n",
    "    def _sigmoid(self,x):\n",
    "        return 1/(1 + np.exp(-x))\n",
    "    \n",
    "    # alternative activation function\n",
    "    def ReLU(self,x):\n",
    "        data = [max(0,value) for value in x]\n",
    "        return np.array(data, dtype=np.float)\n",
    "\n",
    "    # derivation of relu\n",
    "    def ReLU_deriv(self,x):\n",
    "        data = [1 if value>0 else 0 for value in x]\n",
    "        return np.array(data, dtype=np.float)\n",
    "    \n",
    "    def train(self, in_vector, target):\n",
    "        \n",
    "        # make sure that the vectors have the right shape\n",
    "        in_vector = np.array(in_vector)\n",
    "        in_vector = in_vector.reshape(in_vector.size, 1)\n",
    "        if self.bias:\n",
    "            # adding bias node to the input_vector\n",
    "            in_vector = np.concatenate( ([[self.bias]], in_vector) )\n",
    "            \n",
    "        target = np.array(target).reshape(target.size, 1)\n",
    "\n",
    "        # the forward propagation\n",
    "        in_hidden = self._sigmoid(self.w_in_hidden @ in_vector)\n",
    "        #in_hidden = self.ReLU(self.w_in_hidden @ in_vector)\n",
    "        # adding the bias node\n",
    "        if self.bias:\n",
    "            in_hidden = np.concatenate( ([[self.bias]], in_hidden) ) \n",
    "        output = self._sigmoid(self.w_hidden_out @ in_hidden)\n",
    "        #output = self.ReLU(self.w_hidden_out @ in_hidden)\n",
    "        \n",
    "        # the error of the last layer\n",
    "        out_error = target - output\n",
    "        tmp = out_error * output * (1.0 - output)\n",
    "        # tmp = out_error * self.ReLU_deriv(self.w_hidden_out @ in_hidden)\n",
    "        self.w_hidden_out += self.lr  * (tmp @ in_hidden.T)\n",
    "\n",
    "        # the error in the hidden layer:\n",
    "        hidden_errors = self.w_hidden_out.T @ out_error # the backward propagation of the out error\n",
    "        # update the weights:\n",
    "        tmp = hidden_errors * in_hidden * (1.0 - in_hidden)\n",
    "        # tmp = hidden_errors * self.ReLU_deriv(in_hidden)\n",
    "        \n",
    "        if self.bias:\n",
    "            x = (tmp @in_vector.T)[1:,:]     # the first column cut off,\n",
    "        else:\n",
    "            x = tmp @ in_vector.T\n",
    "            \n",
    "        self.w_in_hidden += self.lr * x\n",
    "        \n",
    "        \n",
    "    def run(self, in_vector):\n",
    "        \n",
    "        # make sure that input_vector is a column vector:\n",
    "        in_vector = np.array(in_vector)\n",
    "        in_vector = in_vector.reshape(in_vector.size, 1)\n",
    "        # adding the bias node\n",
    "        if self.bias:\n",
    "            # adding bias node to the input_vector\n",
    "            in_vector = np.concatenate( ([[self.bias]], in_vector) )\n",
    "        \n",
    "        # the forward propagation\n",
    "        in_hidden = self._sigmoid(self.w_in_hidden @ in_vector)\n",
    "        # in_hidden = self.ReLU(self.w_in_hidden @ in_vector)\n",
    "        # adding the bias node\n",
    "        if self.bias:\n",
    "            in_hidden = np.concatenate( ([[self.bias]], in_hidden) ) \n",
    "        output = self._sigmoid(self.w_hidden_out @ in_hidden)\n",
    "        # output = self.ReLU(self.w_hidden_out @ in_hidden)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def evaluate(self, data, labels):\n",
    "        # Counts how often the actual result corresponds to the target result.  \n",
    "        # A result is considered to be correct, if the index of\n",
    "        # the maximal value corresponds to the index with the \"1\"\n",
    "        # in the one-hot representation:\n",
    "        # res = [0.1, 0.132, 0.875]\n",
    "        # labels[i] = [0, 0, 1]\n",
    "        \n",
    "        corrects, wrongs = 0, 0\n",
    "        for i in range(len(data)):\n",
    "            res = self.run(data[i])\n",
    "            res_max = res.argmax()\n",
    "            if res_max == labels[i].argmax():\n",
    "                corrects += 1\n",
    "            else:\n",
    "                wrongs += 1\n",
    "        return corrects, wrongs\n",
    "    \n",
    "    def confusion_matrix(self, data_array, labels):\n",
    "        self.cm = np.zeros((10, 10), int)\n",
    "        for i in range(len(data_array)):\n",
    "            res = self.run(data_array[i])\n",
    "            res_max = res.argmax()\n",
    "            target = labels[i][0]\n",
    "            self.cm[res_max, int(target)] += 1\n",
    "        return self.cm \n",
    "    \n",
    "    def precision(self, label):\n",
    "        col = self.cm[:, label]\n",
    "        return self.cm[label, label] / col.sum()\n",
    "    \n",
    "    def recall(self, label):\n",
    "        row = self.cm[label, :]\n",
    "        return self.cm[label, label] / row.sum()\n",
    "    \n",
    "    def accuracy(self):\n",
    "        diagonal_sum = self.cm.trace()\n",
    "        sum_of_all_elements = self.cm.sum()\n",
    "        return diagonal_sum / sum_of_all_elements\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d769b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p=MLP(n_in=image_pixels, n_out=10, n_hidden=100, lr=0.1, bias=1)\n",
    "    \n",
    "for i in range(len(train_imgs)):\n",
    "    p.train(train_imgs[i], train_labels_one_hot[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd5d842",
   "metadata": {},
   "outputs": [],
   "source": [
    "res=p.run(test_imgs[4])\n",
    "print(res)\n",
    "print(np.max(res))\n",
    "print(np.argmax(res))\n",
    "print(test_labels_one_hot[4])\n",
    "print(np.argmax(test_labels_one_hot[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ecbc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    res = p.run(test_imgs[i])\n",
    "    print(test_labels[i], np.argmax(res), np.max(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdaa6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = p.confusion_matrix(test_imgs, test_labels)\n",
    "print(cm)\n",
    "\n",
    "print(\"accuracy:\", p.accuracy())\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"digit: \", i, \"precision: \", p.precision(i), \"recall: \", p.recall(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55931f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
